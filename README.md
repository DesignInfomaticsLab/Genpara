# ğŸš€ GenPara
**Enhancing 3D Design Editing with Text-Conditional Shape Parameters and Bayesian ROI Inference**  
*CHI 2025 *  

GenPara is an interactive 3D design-editing system that fine-tunes an LLM using Gaussian-blobâ€“based 3D shape parameters and infers each user's Region of Interest (ROI) via Bayesian inference.

---

## ğŸ“„ Paper & Appendix [[url]](https://dl.acm.org/doi/full/10.1145/3706598.3713502)
- Main Paper: GenPara: Enhancing the 3D Design Editing Process by Inferring Usersâ€™ Regions of Interest with Text-Conditional Shape Parameters
- Appendix: Dataset format, fine-tuning structure, HD evaluation metrics

---

# ğŸ“¦ Repository Structure

```
GenPara/
â”‚
â”œâ”€â”€ dataset/
â”‚   â”œâ”€â”€ extrinsic_latents/
â”‚   â”œâ”€â”€ fine_tuning_data/
â”‚   â””â”€â”€ umap_embeddings/
â”‚
â”œâ”€â”€ genpara_frontend/ (to be appear)
â”œâ”€â”€ genpara_backend/  (to be appear)
â”‚   â”œâ”€â”€ inference/
â”‚   â”œâ”€â”€ salad_spaghetti_utils/
â”‚   â””â”€â”€ api/
â”‚
â””â”€â”€ examples/
```

---

# âœ¨ Key Features

### ğŸ”¹ 1. Text-Conditional Part-Level Editing
- Shape edits based on adjectives (e.g., open, curved, thin)
- LLM outputs modified extrinsic latents for 16 Gaussian blobs

### ğŸ”¹ 2. Exploration Map (UMAP)
- Visualizes large-scale 3D design space (~58k chairs)
- Differentiates user-generated vs. LLM-generated vs. ROI-region samples

### ğŸ”¹ 3. Bayesian ROI Inference
- Identifies user interest regions based on recent selections

### ğŸ”¹ 4. Design Versioning Tree
- Hierarchical visualization of all variations and their parentâ€“child relationships

---

# ğŸ”§ Installation

### Requirements
- Python 3.10+
- PyTorch
- UMAP-learn
- OpenAI SDK
- Node.js 18+
- Three.js

Install:
```
pip install -r requirements.txt
```

Initialize submodules:
```
git submodule update --init --recursive
```

---

# ğŸ¯ Using Your Own Dataset for Fine-tuning

GenPara supports fine-tuning using extrinsic latent vectors generated by SALAD/SPAGHETTI.

### 1. Prepare Extrinsic Latent Files
Each model should contain:
- 16 Gaussian blobs
- Each blob: 16 parameters (Mu, eigenvectors, Pi, eigenvalues)

Place JSON files in:
```
dataset/extrinsic_latents/
```

### 2. Create Fine-tuning Dataset (JSONL)
Each record must contain:
- System instruction
- User request describing parts + adjectives
- Assistant output providing adjusted extrinsic latents

### 3. Fine-tune Model
Use OpenAI fine-tuning API:
```
openai api fine_tuning.jobs.create -t dataset/fine_tuning_data/train.jsonl -m gpt-3.5-turbo-1106
```

### 4. Deploy Fine-tuned Model
Model returns full extrinsic latent vectors suitable for reconstruction.

![Uploading genpara_thumbnail_big.gifâ€¦]()

---

# ğŸ—ºï¸ Frontend (Exploration Map & Versioning Tree) 

```
to be appear
```

---

# ğŸ“š Citation

```
@inproceedings{choi2025genpara,
  title={GenPara: Enhancing the 3D Design Editing Process by Inferring Users' Regions of Interest with Text-Conditional Shape Parameters},
  author={Choi, Jiin and Lee, Seung Won and Hyun, Kyung Hoon},
  booktitle={Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
  pages={1--21},
  year={2025}

```

---

# ğŸ™Œ Acknowledgements
GenPara builds on:
- SPAGHETTI
- SALAD
- UMAP
- OpenAI GPT Fine-tuning

